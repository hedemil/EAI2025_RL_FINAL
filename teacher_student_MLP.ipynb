{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training and visualization script for Go1 with height scanner, including student distillation.\"\"\"\n",
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import functools\n",
    "import optax\n",
    "import flax.linen as nn\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from brax.training.agents.ppo import losses as ppo_losses\n",
    "from brax.training.acme import running_statistics\n",
    "import mujoco\n",
    "from mujoco_playground import wrapper\n",
    "from mujoco_playground.config import locomotion_params\n",
    "from custom_env import Joystick, default_config\n",
    "from mujoco_playground._src.gait import draw_joystick_command\n",
    "from IPython.display import HTML, display\n",
    "import mediapy as media\n",
    "import imageio\n",
    "import base64\n",
    "\n",
    "# Set environment variables for GPU usage\n",
    "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "os.environ['XLA_FLAGS'] = xla_flags\n",
    "os.environ['MUJOCO_GL'] = 'egl'\n",
    "\n",
    "# Environment setup\n",
    "xml_path = 'custom_env.xml'\n",
    "env = Joystick(xml_path=xml_path, config=default_config())\n",
    "jit_reset = jax.jit(env.reset)\n",
    "jit_step = jax.jit(env.step)\n",
    "\n",
    "env_cfg = default_config()\n",
    "env_cfg.pert_config.enable = True\n",
    "env_cfg.pert_config.velocity_kick = [0.0, 0.0]\n",
    "env_cfg.pert_config.kick_wait_times = [5.0, 15.0]\n",
    "env_cfg.command_config.a = [1.5, 0.8, 2 * jnp.pi]\n",
    "\n",
    "# Training configuration\n",
    "seed = 42\n",
    "num_envs = 1  # Single environment for simplicity\n",
    "episode_length = 128\n",
    "action_repeat = 1\n",
    "episodes = 10\n",
    "batch_size = 32  # Adjusted for multiple batches\n",
    "batches = episode_length // batch_size\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Discover observation/action shapes from the real env\n",
    "_dummy_key = jax.random.PRNGKey(0)\n",
    "dummy_state = jit_reset(_dummy_key)\n",
    "obs_shape = jax.tree_util.tree_map(lambda x: x.shape, dummy_state.obs)\n",
    "action_size = env.action_size\n",
    "student_obs_dim = int(dummy_state.obs['state'].shape[0])\n",
    "\n",
    "# Teacher network setup (load params saved by train.ipynb)\n",
    "_loaded = np.load(\"params.npy\", allow_pickle=True)\n",
    "# np.save of a tuple can load either as 0-d object array or (3,) object array\n",
    "if getattr(_loaded, 'ndim', 1) == 0:\n",
    "    normalizer_params, policy_params, value_params = _loaded.item()\n",
    "else:\n",
    "    normalizer_params, policy_params, value_params = tuple(_loaded.tolist())\n",
    "teacher_params = (normalizer_params, policy_params, value_params)\n",
    "\n",
    "normalize = running_statistics.normalize\n",
    "ppo_params = locomotion_params.brax_ppo_config('Go1JoystickRoughTerrain')\n",
    "network_factory = ppo_networks.make_ppo_networks\n",
    "if hasattr(ppo_params, 'network_factory'):\n",
    "    network_factory = functools.partial(ppo_networks.make_ppo_networks, **ppo_params.network_factory)\n",
    "\n",
    "# Build teacher network with the SAME observation structure used at training time\n",
    "ppo_network = network_factory(obs_shape, action_size, preprocess_observations_fn=normalize)\n",
    "make_policy = ppo_networks.make_inference_fn(ppo_network)\n",
    "# Teacher inference expects full observation tree (state.obs)\n",
    "jit_inference_fn = jax.jit(make_policy(teacher_params, deterministic=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student network initialized! Input shape: (32, 52), Output shape: (32, 24)\n"
     ]
    }
   ],
   "source": [
    "# Student network definition\n",
    "class StudentPolicy(nn.Module):\n",
    "    action_size: int\n",
    "    hidden_size: int = 100\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(features=self.hidden_size)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.hidden_size)(x)\n",
    "        x = nn.relu(x)\n",
    "        logits = nn.Dense(features=2 * self.action_size)(x)  # Means and log_stds\n",
    "        return logits\n",
    "\n",
    "# Initialize student network\n",
    "student_net = StudentPolicy(action_size=action_size)\n",
    "\n",
    "dummy_input = jnp.ones((batch_size, student_obs_dim))\n",
    "key_student = jax.random.PRNGKey(42)\n",
    "student_params = student_net.init(key_student, dummy_input)\n",
    "optimizer = optax.adamw(learning_rate)\n",
    "opt_state = optimizer.init(student_params)\n",
    "print(f\"Student network initialized! Input shape: {dummy_input.shape}, Output shape: {(batch_size, 2 * action_size)}\")\n",
    "\n",
    "# Evaluation function\n",
    "# policy_fn should be a function: (obs_batch: (1, student_obs_dim), rng) -> logits (1, 2*action_size)\n",
    "def evaluate_policy(env, policy_fn, key, steps=episode_length):\n",
    "    state = jit_reset(key)\n",
    "    total_reward = 0.0\n",
    "    for _ in range(steps):\n",
    "        key, act_key = jax.random.split(key)\n",
    "        obs = state.obs['state']  # use non-privileged observations for student\n",
    "        # Add batch dimension for the network\n",
    "        obs_batch = obs.reshape(1, -1)\n",
    "        logits = policy_fn(obs_batch, act_key)\n",
    "        # Convert mean logits to actions via tanh (teacher deterministic action semantics)\n",
    "        mu = logits[0, :action_size]\n",
    "        actions = jnp.tanh(mu)\n",
    "        state = jit_step(state, actions)\n",
    "        total_reward += state.reward\n",
    "    return float(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison visualization function\n",
    "def compare_teacher_student_gifs(\n",
    "    env,\n",
    "    jit_reset,\n",
    "    jit_step,\n",
    "    teacher_policy_fn,\n",
    "    student_policy_fn,\n",
    "    student_params,\n",
    "    episode_length,\n",
    "    command,\n",
    "    seed,\n",
    "    width=640,\n",
    "    height=480,\n",
    "    fps=30,\n",
    "    render_every=2,\n",
    "):\n",
    "    scene_option = mujoco.MjvOption()\n",
    "    scene_option.geomgroup[2] = True\n",
    "    scene_option.geomgroup[3] = False\n",
    "    scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
    "    scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = False\n",
    "    scene_option.flags[mujoco.mjtVisFlag.mjVIS_PERTFORCE] = True\n",
    "\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    key_teacher, key_student, key_env = jax.random.split(key, 3)\n",
    "\n",
    "    state_teacher = jit_reset(key_env)\n",
    "    state_student = jit_reset(key_env)\n",
    "    state_teacher.info[\"command\"] = command\n",
    "    state_student.info[\"command\"] = command\n",
    "\n",
    "    rollout_teacher = []\n",
    "    rollout_student = []\n",
    "    modify_scene_fns_teacher = []\n",
    "    modify_scene_fns_student = []\n",
    "\n",
    "    for step in range(episode_length):\n",
    "        # Teacher: expects full observation tree\n",
    "        act_rng_teacher, key_teacher = jax.random.split(key_teacher)\n",
    "        ctrl_teacher, _ = teacher_policy_fn(state_teacher.obs, act_rng_teacher)\n",
    "        state_teacher = jit_step(state_teacher, ctrl_teacher)\n",
    "        state_teacher.info[\"command\"] = command\n",
    "        rollout_teacher.append(state_teacher)\n",
    "\n",
    "        # Student: takes non-privileged obs normalized similarly\n",
    "        act_rng_student, key_student = jax.random.split(key_student)\n",
    "        student_obs = state_student.obs['state'].reshape(1, -1)\n",
    "        student_logits = student_policy_fn(student_obs, act_rng_student)\n",
    "        mu = student_logits[0, :env.action_size]\n",
    "        ctrl_student = jnp.tanh(mu)\n",
    "        state_student = jit_step(state_student, ctrl_student)\n",
    "        state_student.info[\"command\"] = command\n",
    "        rollout_student.append(state_student)\n",
    "\n",
    "        for state, modify_scene_fns in [\n",
    "            (state_teacher, modify_scene_fns_teacher),\n",
    "            (state_student, modify_scene_fns_student),\n",
    "        ]:\n",
    "            xyz = np.array(state.data.xpos[env._torso_body_id])\n",
    "            xyz += np.array([0, 0, 0.2])\n",
    "            x_axis = state.data.xmat[env._torso_body_id, 0]\n",
    "            yaw = -np.arctan2(x_axis[1], x_axis[0])\n",
    "            modify_scene_fns.append(\n",
    "                functools.partial(\n",
    "                    draw_joystick_command,\n",
    "                    cmd=state.info[\"command\"],\n",
    "                    xyz=xyz,\n",
    "                    theta=yaw,\n",
    "                    scl=abs(state.info[\"command\"][0]) / env_cfg.command_config.a[0],\n",
    "                )\n",
    "            )\n",
    "\n",
    "    traj_teacher = rollout_teacher[::render_every]\n",
    "    traj_student = rollout_student[::render_every]\n",
    "    mod_fns_teacher = modify_scene_fns_teacher[::render_every]\n",
    "    mod_fns_student = modify_scene_fns_student[::render_every]\n",
    "\n",
    "    frames_teacher = env.render(\n",
    "        traj_teacher,\n",
    "        camera=\"track\",\n",
    "        scene_option=scene_option,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        modify_scene_fns=mod_fns_teacher,\n",
    "    )\n",
    "    frames_student = env.render(\n",
    "        traj_student,\n",
    "        camera=\"track\",\n",
    "        scene_option=scene_option,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        modify_scene_fns=mod_fns_student,\n",
    "    )\n",
    "\n",
    "    teacher_gif_path = \"teacher_policy.gif\"\n",
    "    student_gif_path = \"student_policy.gif\"\n",
    "    # Ensure frames are uint8\n",
    "    frames_teacher = [np.asarray(f, dtype=np.uint8) for f in frames_teacher]\n",
    "    frames_student = [np.asarray(f, dtype=np.uint8) for f in frames_student]\n",
    "    imageio.mimsave(teacher_gif_path, frames_teacher, fps=fps)\n",
    "    imageio.mimsave(student_gif_path, frames_student, fps=fps)\n",
    "\n",
    "    def gif_to_base64(gif_path):\n",
    "        with open(gif_path, \"rb\") as f:\n",
    "            encoded = base64.b64encode(f.read()).decode(\"ascii\")\n",
    "        return f\"data:image/gif;base64,{encoded}\"\n",
    "\n",
    "    teacher_base64 = gif_to_base64(teacher_gif_path)\n",
    "    student_base64 = gif_to_base64(student_gif_path)\n",
    "    html = f\"\"\"\n",
    "    <div style=\"display: flex; justify-content: center;\">\n",
    "        <div style=\"margin-right: 10px; text-align: center;\">\n",
    "            <h3>Teacher Policy</h3>\n",
    "            <img src=\"{teacher_base64}\" width=\"{width}\" height=\"{height}\"/>\n",
    "        </div>\n",
    "        <div style=\"text-align: center;\">\n",
    "            <h3>Student Policy</h3>\n",
    "            <img src=\"{student_base64}\" width=\"{width}\" height=\"{height}\"/>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "    os.remove(teacher_gif_path)\n",
    "    os.remove(student_gif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-03 12:23:30.601248: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-10-03 12:23:30.601271: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-10-03 12:23:30.601284: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-10-03 12:23:30.601292: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-10-03 12:23:30.601301: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-10-03 12:23:30.601307: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.201558\n",
      "Student Eval Reward: 0.010879957117140293\n",
      "\n",
      "Episode 2/10\n",
      "Training Loss: 2.232753\n",
      "Student Eval Reward: 0.0\n",
      "\n",
      "Episode 3/10\n",
      "Training Loss: 3.078645\n",
      "Student Eval Reward: 0.0026649145875126123\n",
      "\n",
      "Episode 4/10\n",
      "Training Loss: 2.758377\n",
      "Student Eval Reward: 0.03197627514600754\n",
      "\n",
      "Episode 5/10\n",
      "Training Loss: 1.637714\n",
      "Student Eval Reward: 0.020274419337511063\n",
      "\n",
      "Episode 6/10\n",
      "Training Loss: 2.913894\n",
      "Student Eval Reward: 0.0\n",
      "\n",
      "Episode 7/10\n",
      "Training Loss: 2.991651\n",
      "Student Eval Reward: 0.0253828763961792\n",
      "\n",
      "Episode 8/10\n",
      "Training Loss: 3.804119\n",
      "Student Eval Reward: 0.5269131660461426\n",
      "\n",
      "Episode 9/10\n",
      "Training Loss: 2.680418\n",
      "Student Eval Reward: 0.0263868048787117\n",
      "\n",
      "Episode 10/10\n",
      "Training Loss: 1.751735\n",
      "Student Eval Reward: 0.005644600838422775\n"
     ]
    }
   ],
   "source": [
    "# Function to get teacher logits\n",
    "@jax.jit\n",
    "def get_teacher_logits(observations):\n",
    "    # observations should be the full observation pytree\n",
    "    param_subset = (teacher_params[0], teacher_params[1])\n",
    "    return ppo_network.policy_network.apply(*param_subset, observations)\n",
    "\n",
    "# Training function with MSE loss\n",
    "@jax.jit\n",
    "def train_step(params, opt_state, inputs, targets):\n",
    "    def loss_fn(params):\n",
    "        predictions = student_net.apply(params, inputs)\n",
    "        loss = jnp.mean((predictions - targets) ** 2)\n",
    "        return loss\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss\n",
    "\n",
    "# Training loop\n",
    "training_losses = []\n",
    "\n",
    "key = jax.random.PRNGKey(seed)\n",
    "for episode in range(episodes):\n",
    "    print(f\"\\nEpisode {episode + 1}/{episodes}\")\n",
    "\n",
    "    key, env_key, act_key = jax.random.split(key, 3)\n",
    "    state = jit_reset(env_key)\n",
    "\n",
    "    raw_command = jax.random.uniform(act_key, shape=(3,), minval=0.0, maxval=1.0)\n",
    "    command = jnp.array([\n",
    "        raw_command[0] * env_cfg.command_config.a[0],\n",
    "        raw_command[1] * env_cfg.command_config.a[1],\n",
    "        raw_command[2] * env_cfg.command_config.a[2]\n",
    "    ])\n",
    "\n",
    "    state.info[\"command\"] = command\n",
    "    student_inputs = jnp.zeros((episode_length, student_obs_dim))\n",
    "    student_targets = jnp.zeros((episode_length, 2 * action_size))\n",
    "    rollout = []\n",
    "    modify_scene_fns = []\n",
    "    \n",
    "    for step in range(episode_length):\n",
    "        act_rng, act_key = jax.random.split(act_key)\n",
    "        # Teacher deterministic action using full observation tree\n",
    "        ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
    "        # Teacher logits target using full observation tree\n",
    "        logits = get_teacher_logits(state.obs)\n",
    "        # Use non-privileged observations as student input\n",
    "        state_flat = state.obs['state']  # shape (student_obs_dim,)\n",
    "        student_inputs = student_inputs.at[step].set(state_flat)\n",
    "        student_targets = student_targets.at[step].set(logits)\n",
    "        state = jit_step(state, ctrl)\n",
    "        state.info[\"command\"] = command\n",
    "        rollout.append(state)\n",
    "        xyz = np.array(state.data.xpos[env._torso_body_id])\n",
    "        xyz += np.array([0, 0, 0.2])\n",
    "        x_axis = state.data.xmat[env._torso_body_id, 0]\n",
    "        yaw = -np.arctan2(x_axis[1], x_axis[0])\n",
    "        modify_scene_fns.append(\n",
    "            functools.partial(\n",
    "                draw_joystick_command,\n",
    "                cmd=state.info[\"command\"],\n",
    "                xyz=xyz,\n",
    "                theta=yaw,\n",
    "                scl=abs(state.info[\"command\"][0]) / env_cfg.command_config.a[0],\n",
    "            )\n",
    "        )\n",
    "    total_loss = 0.0\n",
    "    for batch_idx in range(batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_inputs = student_inputs[start_idx:end_idx]\n",
    "        batch_targets = student_targets[start_idx:end_idx]\n",
    "        student_params, opt_state, loss = train_step(student_params, opt_state, batch_inputs, batch_targets)\n",
    "        total_loss += loss\n",
    "    avg_loss = total_loss / batches\n",
    "    training_losses.append(avg_loss)\n",
    "    print(f\"Training Loss: {float(avg_loss):.6f}\")\n",
    "    # Student inference function: outputs logits\n",
    "    student_policy_fn = jax.jit(lambda obs, rng: student_net.apply(student_params, obs))\n",
    "    # Evaluate: convert logits to actions via tanh(mean)\n",
    "    eval_reward = evaluate_policy(env, student_policy_fn, act_key)\n",
    "    print(f\"Student Eval Reward: {eval_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/EAI2025_RL_FINAL/venv_rl/lib/python3.10/site-packages/glfw/__init__.py:917: GLFWError: (65550) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "/home/jovyan/EAI2025_RL_FINAL/venv_rl/lib/python3.10/site-packages/glfw/__init__.py:917: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    },
    {
     "ename": "FatalError",
     "evalue": "an OpenGL platform library has not been loaded into this process, this most likely means that a valid OpenGL context has not been created before mjr_makeContext was called",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFatalError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m compare_teacher_student_gifs(\n\u001b[1;32m      <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     env\u001b[39m=\u001b[39;49menv,\n\u001b[1;32m      <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     jit_reset\u001b[39m=\u001b[39;49mjit_reset,\n\u001b[1;32m      <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     jit_step\u001b[39m=\u001b[39;49mjit_step,\n\u001b[1;32m      <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     teacher_policy_fn\u001b[39m=\u001b[39;49mjit_inference_fn,\n\u001b[1;32m      <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     student_policy_fn\u001b[39m=\u001b[39;49mstudent_policy_fn,\n\u001b[1;32m      <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     student_params\u001b[39m=\u001b[39;49mstudent_params,\n\u001b[1;32m      <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     episode_length\u001b[39m=\u001b[39;49mepisode_length,\n\u001b[1;32m      <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     command\u001b[39m=\u001b[39;49mjnp\u001b[39m.\u001b[39;49marray([\u001b[39m0.5\u001b[39;49m \u001b[39m*\u001b[39;49m env_cfg\u001b[39m.\u001b[39;49mcommand_config\u001b[39m.\u001b[39;49ma[\u001b[39m0\u001b[39;49m], \u001b[39m0.0\u001b[39;49m, \u001b[39m0.0\u001b[39;49m]),\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     seed\u001b[39m=\u001b[39;49mseed \u001b[39m+\u001b[39;49m episodes,  \u001b[39m# use a stable seed after training\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     width\u001b[39m=\u001b[39;49m\u001b[39m640\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     height\u001b[39m=\u001b[39;49m\u001b[39m480\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     fps\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39m1.0\u001b[39;49m \u001b[39m/\u001b[39;49m env\u001b[39m.\u001b[39;49mdt \u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     render_every\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "\u001b[1;32m/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m mod_fns_teacher \u001b[39m=\u001b[39m modify_scene_fns_teacher[::render_every]\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m mod_fns_student \u001b[39m=\u001b[39m modify_scene_fns_student[::render_every]\n\u001b[0;32m---> <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m frames_teacher \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mrender(\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m     traj_teacher,\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m     camera\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrack\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m     scene_option\u001b[39m=\u001b[39;49mscene_option,\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m     width\u001b[39m=\u001b[39;49mwidth,\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m     height\u001b[39m=\u001b[39;49mheight,\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m     modify_scene_fns\u001b[39m=\u001b[39;49mmod_fns_teacher,\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m frames_student \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mrender(\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m     traj_student,\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m     camera\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrack\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m     modify_scene_fns\u001b[39m=\u001b[39mmod_fns_student,\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://gpu1.eecs.kth.se/home/jovyan/EAI2025_RL_FINAL/teacher_student_MLP.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m teacher_gif_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mteacher_policy.gif\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/EAI2025_RL_FINAL/venv_rl/lib/python3.10/site-packages/mujoco_playground/_src/mjx_env.py:332\u001b[0m, in \u001b[0;36mMjxEnv.render\u001b[0;34m(self, trajectory, height, width, camera, scene_option, modify_scene_fns)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrender\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     trajectory: List[State],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     ] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence[np\u001b[39m.\u001b[39mndarray]:\n\u001b[0;32m--> 332\u001b[0m   \u001b[39mreturn\u001b[39;00m render_array(\n\u001b[1;32m    333\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmj_model,\n\u001b[1;32m    334\u001b[0m       trajectory,\n\u001b[1;32m    335\u001b[0m       height,\n\u001b[1;32m    336\u001b[0m       width,\n\u001b[1;32m    337\u001b[0m       camera,\n\u001b[1;32m    338\u001b[0m       scene_option\u001b[39m=\u001b[39;49mscene_option,\n\u001b[1;32m    339\u001b[0m       modify_scene_fns\u001b[39m=\u001b[39;49mmodify_scene_fns,\n\u001b[1;32m    340\u001b[0m   )\n",
      "File \u001b[0;32m~/EAI2025_RL_FINAL/venv_rl/lib/python3.10/site-packages/mujoco_playground/_src/mjx_env.py:360\u001b[0m, in \u001b[0;36mrender_array\u001b[0;34m(mj_model, trajectory, height, width, camera, scene_option, modify_scene_fns, hfield_data)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrender_array\u001b[39m(\n\u001b[1;32m    348\u001b[0m     mj_model: mujoco\u001b[39m.\u001b[39mMjModel,\n\u001b[1;32m    349\u001b[0m     trajectory: Union[List[State], State],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     hfield_data: Optional[jax\u001b[39m.\u001b[39mArray] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ):\n\u001b[1;32m    359\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Renders a trajectory as an array of images.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m   renderer \u001b[39m=\u001b[39m mujoco\u001b[39m.\u001b[39;49mRenderer(mj_model, height\u001b[39m=\u001b[39;49mheight, width\u001b[39m=\u001b[39;49mwidth)\n\u001b[1;32m    361\u001b[0m   camera \u001b[39m=\u001b[39m camera \u001b[39mif\u001b[39;00m camera \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    363\u001b[0m   \u001b[39mif\u001b[39;00m hfield_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/EAI2025_RL_FINAL/venv_rl/lib/python3.10/site-packages/mujoco/renderer.py:89\u001b[0m, in \u001b[0;36mRenderer.__init__\u001b[0;34m(self, model, height, width, max_geom, font_scale)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gl_context:\n\u001b[1;32m     88\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gl_context\u001b[39m.\u001b[39mmake_current()\n\u001b[0;32m---> 89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mjr_context \u001b[39m=\u001b[39m _render\u001b[39m.\u001b[39;49mMjrContext(model, font_scale\u001b[39m.\u001b[39;49mvalue)\n\u001b[1;32m     90\u001b[0m _render\u001b[39m.\u001b[39mmjr_setBuffer(\n\u001b[1;32m     91\u001b[0m     _enums\u001b[39m.\u001b[39mmjtFramebuffer\u001b[39m.\u001b[39mmjFB_OFFSCREEN\u001b[39m.\u001b[39mvalue, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mjr_context\n\u001b[1;32m     92\u001b[0m )\n\u001b[1;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mjr_context\u001b[39m.\u001b[39mreadDepthMap \u001b[39m=\u001b[39m _enums\u001b[39m.\u001b[39mmjtDepthMap\u001b[39m.\u001b[39mmjDEPTH_ZEROFAR\n",
      "\u001b[0;31mFatalError\u001b[0m: an OpenGL platform library has not been loaded into this process, this most likely means that a valid OpenGL context has not been created before mjr_makeContext was called"
     ]
    }
   ],
   "source": [
    "compare_teacher_student_gifs(\n",
    "    env=env,\n",
    "    jit_reset=jit_reset,\n",
    "    jit_step=jit_step,\n",
    "    teacher_policy_fn=jit_inference_fn,\n",
    "    student_policy_fn=student_policy_fn,\n",
    "    student_params=student_params,\n",
    "    episode_length=episode_length,\n",
    "    command=jnp.array([0.5 * env_cfg.command_config.a[0], 0.0, 0.0]),\n",
    "    seed=seed + episodes,  # use a stable seed after training\n",
    "    width=640,\n",
    "    height=480,\n",
    "    fps=int(1.0 / env.dt / 2),\n",
    "    render_every=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
