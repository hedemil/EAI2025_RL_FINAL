{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"Visualization script for Go1 with height scanner.\"\"\"\n",
    "import os\n",
    "import subprocess\n",
    "# Tell XLA to use Triton GEMM\n",
    "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "os.environ['XLA_FLAGS'] = xla_flags\n",
    "os.environ['MUJOCO_GL'] = 'egl'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jp\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from brax.training.agents.ppo import losses as ppo_losses\n",
    "\n",
    "import mujoco\n",
    "from mujoco_playground import wrapper\n",
    "from mujoco_playground import registry\n",
    "from mujoco_playground.config import locomotion_params\n",
    "from custom_env import Joystick, default_config\n",
    "\n",
    "from datetime import datetime\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import functools\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import Image as IPyimage, display, HTML, clear_output\n",
    "\n",
    "from utils import render_video_during_training, evaluate_policy\n",
    "\n",
    "scene_option = mujoco.MjvOption()\n",
    "scene_option.geomgroup[2] = True   # Show visual geoms\n",
    "scene_option.geomgroup[3] = False  # Hide collision geoms\n",
    "scene_option.geomgroup[5] = True   # Show sites (including height scanner visualization)\n",
    "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True  # Show contact points\n",
    "scene_option.flags[mujoco.mjtVisFlag.mjVIS_RANGEFINDER] = True\n",
    "print(\"Creating Visualization...\")\n",
    "\n",
    "xml_path = 'custom_env.xml' # 'custom_env_debug_wall.xml'\n",
    "env = Joystick(xml_path=xml_path, config=default_config())\n",
    "\n",
    "# JIT compile the functions for speed\n",
    "jit_reset = jax.jit(env.reset)\n",
    "jit_step = jax.jit(env.step)\n",
    "jit_terrain_height = jax.jit(env._get_torso_terrain_height)\n",
    "\n",
    "seed = 1234\n",
    "num_envs = ()\n",
    "key = jax.random.PRNGKey(seed)\n",
    "key, key_env, eval_key, key_policy, key_value = jax.random.split(key, 5)\n",
    "key_envs = jax.random.split(key_env, num_envs)\n",
    "env_state = jit_reset(key_envs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher Policy\n",
    "\n",
    "- pretrained inside train.ipynb\n",
    "- we want to load the parameters\n",
    "\n",
    "- Inputs: privileged_state with heightmap\n",
    "- Output: action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters for pre-trained teacher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from brax.training.agents.ppo import losses as ppo_losses\n",
    "\n",
    "# Needs to match training\n",
    "obs_shape = (52,)\n",
    "normalize = lambda x, y: x\n",
    "action_size = env.action_size\n",
    "\n",
    "# Setup\n",
    "ppo_params = locomotion_params.brax_ppo_config('Go1JoystickRoughTerrain')\n",
    "network_factory = ppo_networks.make_ppo_networks\n",
    "if \"network_factory\" in ppo_params:\n",
    "    network_factory = functools.partial(\n",
    "        ppo_networks.make_ppo_networks,\n",
    "        **ppo_params.network_factory\n",
    "    )\n",
    "\n",
    "ppo_network = network_factory(\n",
    "    obs_shape, action_size, preprocess_observations_fn=normalize\n",
    ")\n",
    "\n",
    "init_params = ppo_losses.PPONetworkParams(\n",
    "    policy=ppo_network.policy_network.init(key_policy),\n",
    "    value=ppo_network.value_network.init(key_value),\n",
    ")\n",
    "\n",
    "# Create policy function\n",
    "make_policy = ppo_networks.make_inference_fn(ppo_network)\n",
    "\n",
    "params = np.load(\"params.npy\", allow_pickle=True)\n",
    "\n",
    "jit_inference_fn = jax.jit(make_policy(params, deterministic=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Policy\n",
    "\n",
    "Experiment 1: training with a newly initialized LSTM for a Recurrent Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Definition\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import flax.linen as nn\n",
    "\n",
    "lstm = nn.RNN(nn.LSTMCell(features=64))\n",
    "x = jnp.ones((10, 50, 52)) # (batch, time, features)\n",
    "variables = lstm.init(jax.random.PRNGKey(0), x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_ppo_train import _maybe_wrap_env\n",
    "\n",
    "seed = 1234\n",
    "\n",
    "episodes = 1\n",
    "envs_per_episode = 1\n",
    "episode_length = 1000\n",
    "action_repeat = 1\n",
    "\n",
    "learning_rate = 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mujoco_playground._src.gait import draw_joystick_command\n",
    "env_cfg = default_config()\n",
    "\n",
    "# Loop over \"runs\"\n",
    "for episode in range(episodes):\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    key, key_env, eval_key, key_policy, key_value = jax.random.split(key, 5)\n",
    "\n",
    "    wrapper_env = _maybe_wrap_env(\n",
    "        env,\n",
    "        wrap_env=True,\n",
    "        num_envs=envs_per_episode,\n",
    "        episode_length=episode_length,\n",
    "        action_repeat=action_repeat,\n",
    "        key_env=key_env,\n",
    "    )\n",
    "\n",
    "    # Reset environment \n",
    "    reset_fn = jax.jit(env.reset)\n",
    "    key_envs = jax.random.split(key_env, num_envs)\n",
    "    env_state = reset_fn(key_envs)\n",
    "    # print(f\"ENV STATE: {env_state.done}\")\n",
    "    obs_shape = jax.tree_util.tree_map(lambda x: x.shape[1:], env_state.obs)\n",
    "    # print(f\"OBS STATE: {env_state.obs}\")\n",
    "\n",
    "\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    command = jax.random.uniform(rng, shape=(3), minval=0.0, maxval=1.0)\n",
    "    state = jit_reset(rng)\n",
    "    state.info[\"command\"] = command\n",
    "\n",
    "    # Visualisation storing\n",
    "    rollout = []\n",
    "    modify_scene_fns = []\n",
    "\n",
    "    # Training data storing\n",
    "    teacher_obs = []\n",
    "\n",
    "    for _ in range(episode_length): # NOT DOING DONE: CHECK .done? - what does done even mean\n",
    "        \n",
    "        # Get new action\n",
    "        act_rng, rng = jax.random.split(rng)\n",
    "        ctrl, _ = jit_inference_fn(state.obs, act_rng) # we want to save ctrl?? \n",
    "\n",
    "        # Get new state based on action\n",
    "        state = jit_step(state, ctrl)\n",
    "        state.info[\"command\"] = command\n",
    "\n",
    "        \n",
    "        # Visualisation\n",
    "        rollout.append(state)\n",
    "        xyz = np.array(state.data.xpos[env._torso_body_id])\n",
    "        xyz += np.array([0, 0, 0.2])  # Offset for visualization\n",
    "        x_axis = state.data.xmat[env._torso_body_id, 0]\n",
    "        yaw = -np.arctan2(x_axis[1], x_axis[0])\n",
    "        modify_scene_fns.append(\n",
    "            functools.partial(\n",
    "                draw_joystick_command,\n",
    "                cmd=state.info[\"command\"],\n",
    "                xyz=xyz,\n",
    "                theta=yaw,\n",
    "                scl=abs(state.info[\"command\"][0]) / env_cfg.command_config.a[0],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    \n",
    "    # Rendering config\n",
    "    render_every = 2  # Frame skip for smoother visualization\n",
    "    fps = 1.0 / env.dt / render_every\n",
    "    traj = rollout[::render_every]\n",
    "    mod_fns = modify_scene_fns[::render_every]\n",
    "\n",
    "    scene_option = mujoco.MjvOption()\n",
    "    scene_option.geomgroup[2] = True  # Show visual geoms\n",
    "    scene_option.geomgroup[3] = False  # Hide collision geoms\n",
    "    scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
    "    scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = False\n",
    "    scene_option.flags[mujoco.mjtVisFlag.mjVIS_PERTFORCE] = True\n",
    "\n",
    "    # Render\n",
    "    frames = env.render(\n",
    "    traj,\n",
    "    camera=\"track\",\n",
    "    scene_option=scene_option,\n",
    "    width=640,\n",
    "    height=480,\n",
    "    modify_scene_fns=mod_fns,\n",
    "    )   \n",
    "    media.show_video(frames, fps=fps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # if normalize_observations:\n",
    "    #     normalize = running_statistics.normalize\n",
    "\n",
    "    # optimizer = optax.adam(learning_rate=learning_rate)\n",
    "\n",
    "    # loss_fn = #\n",
    "\n",
    "    # gradient_update_fn = #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_inference_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "    \n",
    "while not done:\n",
    "    act_rng, rng = jax.random.split(rng)\n",
    "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
    "    done = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinalRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
